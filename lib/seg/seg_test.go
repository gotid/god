package seg

import (
	"fmt"
	"testing"
	"time"
)

var (
	// åˆ é™¤è¯
	StopWords = []string{
		"è®¾è®¡",
		"çµæ„Ÿ",
		"é£æ ¼",
	}

	// åˆå¹¶è¯
	CombineWords = []string{
		"benjamin moore",
		"setting wall",
	}

	// åˆæˆè¯æ˜ å°„
	CombineMap = map[string]string{
		"art deco": "art-deco",
		//"å¤å¤ æœªæ¥":    "å¤å¤æœªæ¥ä¸»ä¹‰",
	}

	// åŒä¹‰è¯æ˜ å°„
	SynonymMap = map[string]string{
		"ç„å…³":          "é—¨å…",
		"ç™½":           "ç™½è‰²",
		"ç»¿":           "ç»¿è‰²",
		"ç²‰":           "ç²‰è‰²",
		"è“":           "è“è‰²",
		"çº¢":           "çº¢è‰²",
		"é»„":           "é»„è‰²",
		"ç°":           "ç°è‰²",
		"ç´«":           "ç´«è‰²",
		"æ©™":           "æ©™è‰²",
		"æ©˜":           "æ©˜è‰²",
		"æ£•":           "æ£•è‰²",
		"é»‘":           "é»‘è‰²",
		"å¤§åœ°è‰²":         "å¤§åœ°è‰²ç³»",
		"é©¬å¡é¾™":         "é©¬å¡é¾™è‰²",
		"è«å…°è¿ª":         "è«å…°è¿ªè‰²",
		"è§å…‰":          "è§å…‰è‰²",
		"é‡‘":           "é‡‘è‰²",
		"é“¶":           "é“¶è‰²",
		"settingwall": "èƒŒæ™¯å¢™",
		"è¯§å¯‚":          "ä¾˜å¯‚",
		"å¤å¤æœªæ¥":        "å¤å¤æœªæ¥ä¸»ä¹‰",
	}
)

func TestSeg_CutForSearch(t *testing.T) {
	segmenter := NewSegmenter(
		"dict.txt",
		StopWords,
		CombineWords,
		CombineMap,
		SynonymMap,
		[][]string{},
		false,
	)

	q := "å®¢å… ç°ä»£ è½»å¥¢ çº¢è‰²æˆ¿å­"
	// q = "æ²™å‘ ç°ä»£ ç™½å®¢å…"
	// q = "æ²™å‘åŒºæ€ä¹ˆæ­é…å¤§ç†çŸ³"
	// q = "é…’åº— å¤§ç†çŸ³ æ²™å‘"
	// q = "å«ç”Ÿé—´ ç™½è‰²ç“·ç –å¢™é¢"
	// q = "å«ç”Ÿé—´ å¢™ç –"
	// q = "imolaç™½è‰²ç“·ç –"
	// q = "ç“·ç – fasfj ğŸ˜„ ç™½è‰²"
	// q = "å²›å° ç“·ç –"
	q = "çº¢è‰²æ²™å‘ ç™½è‰²çª—å¸˜"
	start := time.Now().UnixMicro()
	keywords := segmenter.CutForSearch(q, 6, false)
	fmt.Println("âŒšï¸ è€—æ—¶", time.Now().UnixMicro()-start, "å¾®ç§’")

	for i, keyword := range keywords {
		fmt.Println(i, keyword.Word, keyword.Tag, keyword.Distance, keyword.Weight)
	}
}
